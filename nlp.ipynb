{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 외부에서 파일을 불러올 때 os가 있으면 편하다. os자원을 제어할 수 있게 해주는 모듈이다. nltk파일을 불러올 때 os와 함께 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'a man in the house' # untokenized string\n",
    "t = ['a', 'man', 'in', 'the', 'house'] # tokenized seqeuence of words as a list\n",
    "# t=s.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s에 string이 담겨 있고 s를 split해서 tokenize하면 t가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: a man in the house...>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nltk.Text(t)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t를 nltk의 text형식으로 바꿔주어야 nltk의 여러가지 함수들을 적용하기 편하다.\n",
    "#### nltk의 Text()함수를 이용해서 바꿔준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: a man in the house...>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.Text(s.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s에 split()함수를 적용하면 t와 같아지기 때문에 nltk.Text(t)와 동일한 결과값을 가지게 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SAMSUNG\\\\Desktop\\\\OneDrive - 고려대학교\\\\bamsimee'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### os.getcwd()함수는 현재 디렉토리 경로를 불러온다. 경로를 구분할 때 \\백슬래시가 사용되는데 문자그대로의 백슬래시를 나타내려면 \\\\를 두 번 입력해줘야한다. 따라서 출력된 경로에 \\\\가 들어가 있는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw = open(os.getcwd()+r'/06_01.txt', encoding = 'utf8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### os.getcwd()함수로 현재 디렉토리경로를 불러온 후 거기에 위치한 '06_01.txt'을 덧붙여 파일경로를 완성하고 open함수를 이용해 불러온다. 텍스트파일을 불러오는 것이기 때문에 utf8로 인코딩을 해준 후 read함수를 이용해 불러온다. 이 텍스트를 raw로 받는다.\n",
    "#### 특수문자들은 파이썬에서 다양한 기능을 하게 되는데 이 특수문자들을 순수한 문자열 자체로 사용하기 위해서는 raw문자열로 바꿔주어야 한다. 인용부호 앞에 r을 붙이면 뒤의 문자열을 rawstring으로 만들 수 있다. \n",
    "#### 백슬래시는 이스케이프문자로 기능을 갖기 때문에 경로를 나타낼 때의 순수한 문자로 사용하려면  \\\\로 두 개를 연속으로 치거나 맨 앞에 r을 사용하여 raw string으로 만들어줘야한다. 경로를 표시할 때에 /슬래시를 사용할 수도 있다. 따라서 여기에서는 굳이 r를 붙여주지 않아도 경로를 찾는 데 문제가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "1154507\n",
      "The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(raw))\n",
    "print(len(raw))\n",
    "print(raw[:75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### raw의 type은 str이고 길이는 1154507으로 총 1154507개의 character가 있다고 보면 된다. str이기 때문에 str의 index를 이용해서 부분만 출력할 수 있다. 여기서는 처음부터 75미만의 index를 출력하므로 총 0~74번째 character가 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "257726\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "print(type(tokens))\n",
    "print(len(tokens))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### str인 raw를 nltk안에 있는 word_tokenize라는 함수를 이용하여 tokenize시킨다. split과 같지만 split은 특정문자를 기준으로 (보통 스페이스) 나누지만 word_tokenize는 좀 더 세련된 기능으로 ','나 ':'같은 문장부호들도 따로따로 나눠주어서 더욱 유용하게 활용할 수 있다. 결과 값을 tokens에 받아준다.\n",
    "#### type은 리스트이며 토큰화되었기 때문에 길이는 단어의 갯수와 비슷할 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.text.Text'>\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Ilya Petrovitch; Project\n",
      "Gutenberg; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(type(text))\n",
    "print(text[:10])\n",
    "text.collocations()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text함수는 str의 타입을 nltk.text.Text(nltk전용 variable)로 바꿔준다. 출력해보면 겉보기에는 전의 list화된 tokens와 달라진 것이 없어보이지만 nltk전용 함수들을 사용할 수 있게된다. tokens를 nltk text화 시킨 값을 text에 받는다.\n",
    "#### text에 nltk전용 함수인 collocations()함수를 사용하면 같이나올 가능성이 높은 두 단어들을 pair로 묶어준다. 각 pair들은 ;으로 구분이 되고 이 text에서는 주로 사람이름이 해당된다. nltk전용 variable로 만들어줌으로써 collocation함수가 복잡한 분석을 대신 해주는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 162 matches:\n",
      "and were more frequent in periods of great strain . In 1859 he was allowed to r\n",
      "ndency and of late she had read with great interest a book she got through Mr. \n",
      " the bosom of her family ... . And a great deal more ... . Quite excusable , si\n",
      "that you had heard that Dounia had a great deal to put up with in the Svidrigra\n",
      "g will she has . Dounia can endure a great deal and even in the most difficult \n",
      " that letter she reproached him with great heat and indignation for the basenes\n",
      "putation ; they had seen and known a great deal more than Mr. Svidrigailov had \n",
      "n other people ’ s . In my opinion a great deal , a very great deal of all this\n",
      " In my opinion a great deal , a very great deal of all this was unnecessary ; b\n",
      " . He is a very busy man and is in a great hurry to get to Petersburg , so that\n",
      " me that , though he is not a man of great education , he is clever and seems t\n",
      " very well . Of course , there is no great love either on his side , or on hers\n",
      "tted the matter has been arranged in great haste . Besides he is a man of great\n",
      "great haste . Besides he is a man of great prudence and he will see , to be sur\n",
      "d that she is ready to put up with a great deal , if only their future relation\n",
      " off for Petersburg , where he has a great deal of business , and he wants to o\n",
      "a or I breathed a word to him of the great hopes we have of his helping us to p\n",
      "ites that ‘ Dounia can put up with a great deal. ’ I know that very well . I kn\n",
      "at , that ‘ Dounia can put up with a great deal. ’ If she could put up with Mr.\n",
      "it , she certainly can put up with a great deal . And now mother and she have t\n",
      "e young , and she was walking in the great heat bareheaded and with no parasol \n",
      "f the skirt , close to the waist : a great piece was rent and hanging loose . A\n",
      "ts or conversations . He worked with great intensity without sparing himself , \n",
      " uproarious and was reputed to be of great physical strength . One night , when\n",
      ". His legs felt suddenly heavy and a great drowsiness came upon him . He turned\n"
     ]
    }
   ],
   "source": [
    "text.concordance('great', 79, 25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nltk함수인 concordanc()함수는 input에 찾는 단어와 숫자 두 개를 넣으면 해당단어를 text에서 찾아내고 그 단어를 중심으로 앞 뒤를 합쳐 input 두 번째에 해당하는 숫자만큼의 character를 찾는다. 이것을 input세 번째에 해당하는 숫자만큼 반복하여 찾는 것이다. 따라서 두 번째 숫자는 횡의 길이를, 세 번째 숫자는 종의 길이를 나타낸다.\n",
    "#### 여기서는 text에서 great을 모두 찾은 후 처음부터 총 25개의 sample을 따온다. 문맥을 알 수 있도록 great을 중심으로 양쪽으로 총 79개의 character를 보는 것이다. 영어공부나 교재만들기에 활용할 수 있을 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Moby Dick by Herman Melville 1851]\n",
      "\n",
      "\n",
      "ETYMOLOGY.\n",
      "\n",
      "(Supplied by a Late Consumptive Usher to a Grammar School)\n",
      "\n",
      "The pale Usher--threadbare in coat, heart, body, and brain; I see him\n",
      "now.  He was\n",
      "[(' ', 198098), ('e', 115855), ('t', 85539), ('a', 75266), ('o', 68338), ('n', 64431), ('s', 62022), ('i', 61891), ('h', 61434), ('r', 51311)]\n"
     ]
    }
   ],
   "source": [
    "raw = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "\n",
    "print(raw[:200])\n",
    "fdist = nltk.FreqDist(raw)\n",
    "print(fdist.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nltk라이브러리에는 함수 뿐만아니라 데이터도 들어있다. 여기서는 그 중 corpus폴더의 gutenberg폴더에 들어있는 모비딕melville-moby_dick.txt 텍스트를 raw데이터로 불러오고 raw에 할당했다. raw의 type은 str이다.\n",
    "#### raw에 Freqdist()함수를 사용하여 most frequent한 character를 찾을 수 있다. 이 함수는 tokenize하지 않아도 사용가능하고, nltk 요소가 아니더라도 사용가능하다. 여기서는 str인 raw에 적용하였다.\n",
    "#### 위에서 구한 most frequent 값을 보려면 그 값을 받은 fdist에 most_common()함수를 이용하여 보고싶은 순위까지를 입력하여 출력하면 된다. input에 10을 넣으면 most common10위까지가 해당 character와 distribution(빈도)가 tuple을 이루고 각 tuple들이 list를 이뤄서 출력된다.\n",
    "#### raw str에서 가장 common한 것은 스페이스바이며 총 198098번 쓰인 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('e', 117092), ('t', 87996), ('a', 77916), ('o', 69326), ('n', 65617)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e', 't', 'a', 'o', 'n']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())\n",
    "print(fdist.most_common(5))\n",
    "[char for (char, count) in fdist.most_common(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list안에 for loop를 넣을 수 있다. raw의 각 character를 ch로 받는데 조건에 isalpha()를 이용해서 문장부호 등은 빼고 알파벳문자만 받아오는 함수이다. 이렇게 받은 ch를 .lower()함수를 이용하여 소문자로 받아온다. isaplpha()와 lower()는 str과 반응한다. 여기서는 결과적으로 문장부호를 모두 제외하고 대문자들이 소문자로 바뀌어서 list로 받아진다.\n",
    "#### 이렇게 받아진 list에 Freqdist함수에 집어넣어 most common character정보를 만들고 fdist에 받는다.\n",
    "#### 마지막 list안에 for loop를 이용하여 fdist에 most_common()기능을 이용하면 가장 흔한 5개의 character가 distribution과 함께  튜플형태로 받아진다. 이것을 (char, count)의 튜플형태의 변수로 받는다. 튜플이 5개가 만들어지니까 for loop는 5회 돌아갔다고 볼 수 있다. 마지막으로 list안에는 그 중 char의 값을 받는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zymosis',\n",
       " 'zymosterol',\n",
       " 'zymosthenic',\n",
       " 'zymotechnic',\n",
       " 'zymotechnical',\n",
       " 'zymotechnics',\n",
       " 'zymotechny',\n",
       " 'zymotic',\n",
       " 'zymotically',\n",
       " 'zymotize',\n",
       " 'zymotoxic',\n",
       " 'zymurgy',\n",
       " 'Zyrenian',\n",
       " 'Zyrian',\n",
       " 'Zyryan',\n",
       " 'zythem',\n",
       " 'Zythia',\n",
       " 'zythum',\n",
       " 'Zyzomys']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.words.words('en')[-20:-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nltk라이브러리에는 영어사전도 들어있다. 파일 경로를 .으로 구분하여 en파일을 불러온다. en파일은 단어(str)로 이루어진 list이다. 여기서 뒤에서 20번째부터 마지막 index를 갖는 단어를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235886"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.words.words('en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nltk라이브러리 안, corpus폴더 안, words폴더 안의 단어의 리스트인 'en'의 길이를 본다. 단어의 list이므로 길이는 list 속 단어의 갯수가 될 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
